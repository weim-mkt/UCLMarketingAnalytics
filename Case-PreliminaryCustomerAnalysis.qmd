---
title: "Descriptive Analytics: Preliminary Customer Analysis"
author: Dr Wei Miao
subtitle: "MSIN0094 Case Study"
institute: UCL School of Management
date: "`r (lubridate::ymd('20221006')+lubridate::dweeks(2))|> format('%a, %d %b')`"
df-print: kable
colorlinks: true
code-line-numbers: true
format:
  html: 
    toc: true
    number-sections: true
    page-layout: full
    toc-depth: 2
    code-line-numbers: true
    code-copy: hover
  pdf: 
    number-sections: true
    toc: false
    number-depth: 2
    fontsize: 9pt
    linestretch: 1.25
knitr:
  opts_chunk:
    echo: true
    warning: false
    message: false
    error: false
bibliography: references.bib
editor_options: 
  chunk_output_type: inline
---

# The Power of Descriptive Analytics

The amount of data created worldwide has been increasing exponentially over the past decade with some estimates placing the total at 59 zettabytes as of 2020 (Statista 2020). Data without analytics, however, is of little value to business decision-makers aiming to improve performance and increase growth. It is therefore no surprise that top-tier consulting companies, analytics ﬁrms and business schools have been promoting the positive returns to greater usage of analytics technology. It also explains why an increasing number of data analytics enthusiasts are willing to pay up to £40k tuition fee (that is 10,000 bubble teas!) to join the prestigious MSc Business Analytics program at the UCL School of Management (hmm, it's now week 3, too late to ask for a refund!).

By identifying patterns and trends in massive amounts of data, business analytics enables organizations to make better decisions and improve performance. Descriptive analytics is the simplest and most widely used type of analytics; it is used to generate key performance indicators (KPIs) and metrics for business reports and dashboards. The latest research shows that, even with the adoption of very simple descriptive analytics, businesses can improve their performance by a large extent --- @bermanValueDescriptiveAnalytics2022 use the synthetic difference-in-differences method to analyze the staggered adoption of a retail analytics dashboard by more than 1,500 e-commerce websites,[^1] and find an increase of 4%--10% in average weekly revenues postadoption. The increase in revenue is not explained by price changes or advertising optimization. Instead, it is consistent with the addition of customer relationship management, personalization, and prospecting technologies to retailer websites. The adoption and usage of descriptive analytics also increases the diversity of products sold, the number of transactions, the numbers of website visitors and unique customers, and the revenue from repeat customers. These findings are consistent with a complementary effect of descriptive analytics that serve as a monitoring device that helps retailers control additional martech tools and amplify their value. Without using the descriptive dashboard, retailers are unable to reap the benefits associated with these technologies.

[^1]: We will cover the difference-in-differences technique to establish causal inference later in the module.

In practice, businesses use descriptive analytics to assess how well they are performing and if they are on pace to meet business objectives. Business leaders and financial specialists monitor common financial measures generated by descriptive analytics, such as revenue and spending growth on a regular basis. Marketing teams utilize descriptive analytics to analyze the efficacy of marketing campaigns by tracking data such as conversion rates and social media followers, and manage customer relationship by keeping track of customer lifetime values. Manufacturing organizations track indicators such as line throughput and downtime. Descriptive analytics enables everyone in the organization to make more informed decisions that move the business forward. It reveals trends that would otherwise remain buried in raw data, allowing marketing managers to quickly assess how well the firm is operating and identify areas for improvement. Additionally, descriptive analytics enables firms to convey information within departments and to external parties.

In the remaining of this case, we will explore (1) how to consolidate multiple databases from various sources using R and (2) how to conduct preliminary customer analysis using descriptive analytics.

# Database Marketing at Tesco

We have learned in Week 2, how to compute the customer lifetime value for i-basket, an online grocery store. However, when computing the CLV, we used an "average" approach, which did not consider customer heterogeneity. That is, when considering each component in the CLV formula, such as customer spending in each period, their retention rate, etc., we took the average across all customers, and assumed customers are homogeneous. As a result, every customer would have the same CLV. Nevertheless, this is a strong assumption in practice --- every customer is unique and should be treated differently.

The key to successful customer relationship management is to maintain a customer database that tracks detailed customer information, including their demograhpic information and past purchase history. This information would empower marketing analytics team to compute individual CLV for each customer, and conduct individualized targeted marketing.

## Demographic Information

Knowing your consumer is a vital concept of running any business. Is the business selling fertilizer to farmers, apparel to teenage girls, or vacations to senior citizens? The distinctions are readily apparent in this comparison.

Demographics define the qualities of clients. To be successful, business owners must understand the demographics of their clients and the trends or changes that are occurring within those specific traits.

The following demographic information is usually of interest to business managers:

*Age*: Consumer behavior is strongly influenced by age. Younger consumers are more affluent and willing to spend more on entertainment, fashion, and movies. Seniors spend less on these items; they are less active, spend more time indoors, and require more medical treatment. Additionally, market segments can be defined by age groups. For instance, digital devices such as iPhones are targeted more towards millennials than at seniors. While older adults are increasingly utilizing technology, they remain less digitally savvy than millennials and purchase fewer digital products.

*Gender*: Gender also matters. Males and females have vastly diverse demands and tastes, which influence their purchasing decisions. As a result, some products are created with a specific gender in mind. Macy's, Nordstrom, and The Gap all have departments dedicated to teenage girls' clothes, while Seiko has a specific line of diver watches for men only.

*Income*: Income has a substantial influence on consumer behavior and product purchases. Middle-income customers make purchases with due regard for the utility of money. They do not have unlimited money to spend, and hence the money spent on one item may be used on something else. On the other hand, consumers with higher incomes tend to be less price sensitive and have a higher willingness to pay.

*Education*: Consumers' level of education has an effect on their impressions of the world around them and on the amount of research they conduct prior to making a purchase. Individuals with a higher level of education will spend more time educating themselves before investing their money. Education has an impact on fashion, film, and television programming. Consumers with a higher level of education can be more distrustful of commercials and the facts offered.

Tesco has collected rich customer demographic information through its loyalty program, Tesco Clubcard membership. In the demograhpics.csv dataset, the data scientist team has the following demographic variables:

-   ID: Customer's unique identifier
-   Year_Birth: Customer's birth year
-   Education: Customer's education level
-   Marital_Status: Customer's marital status
-   Income: Customer's yearly household income
-   Kidhome: Number of children in customer's household
-   Teenhome: Number of teenagers in customer's household
-   Dt_Customer: Date of customer's enrollment with the company

## Purchase History

"History doesn't repeat itself, but it often rhymes."

This popular aphorism, frequently (and perhaps incorrectly) attributed to Mark Twain, is frequently invoked to demonstrate that, while past events do not always provide a clear indication of future events, they do provide valuable context. This sentiment is especially true for marketing managers, where a consumer's purchase history provides invaluable insight into their future purchasing habits.

Tesco's data engineering team has assembled a cross-sectional customer purchase history data, with variables including

-   ID: Customer's unique identifier
-   MntWines: Amount spent on wine in last 2 years
-   MntFruits: Amount spent on fruits in last 2 years
-   MntMeatProducts: Amount spent on meat in last 2 years
-   MntFishProducts: Amount spent on fish in last 2 years
-   MntSweetProducts: Amount spent on sweets in last 2 years
-   NumDealsPurchases: Number of purchases made with a discount
-   NumWebPurchases: Number of purchases made through the company's web site
-   NumCatalogPurchases: Number of purchases made using a catalogue
-   NumStorePurchases: Number of purchases made directly in stores
-   NumWebVisitsMonth: Number of visits to company's web site in the last month
-   Complain: 1 if customer complained in the last 2 years, 0 otherwise
-   Response: 1 if customer accepted the offer in the last campaign, 0 otherwise
-   Recency: Number of days since customer's last purchase

# Data Wrangling

## Data Loading

To work on the datasets, we first need to load the raw data into R. The demographic information data are stored as csv files. In R, we can use read.csv(filepath) to load the data into R environment.

For your convenience, I have stored the `demographic.csv` and purchase.csv files on my Dropbox. We can directly feed the url links to `read.csv()` to download and create the dataset.

```{r}
## use read.csv() to download and load the data, assign it to an R data object
## header = T argument is to tell read.csv() to keep the dataset header (first row)

# Load demograhpic data, and call it data_demo
data_demo <- read.csv(file = "https://www.dropbox.com/s/a0v38lpydls2emy/demographics.csv?dl=1",
                      header = T)

# Load purchase history data, and call it data_purchase
data_purchase <- read.csv(file = "https://www.dropbox.com/s/de435r8zdxydnhg/purchase.csv?dl=1" , header = T)

```

After running the above code blocks, you should see two datasets in your RStudio environment.

Now, click into each dataset, take a look, and get a sense of how these two datasets look like.

## Data Consolidation

In reality, to accomplish a data analytics task, data scientists often need to collect data from various sources, and assemble them into a larger dataset as needed.

Now we have two Tesco datasets at hand, and we should assemble them into a larger data frame.

-   Merge the demographic information into purchase history data. Name the joined data as "data_full"

    -   try left_join(), right_join(), inner_join(), and full_join().

    -   Do they give you the same results? Why? When would you get different results?

```{r}
pacman::p_load(dplyr)
# left join
data_full <- data_purchase %>%
  left_join(data_demo, by = "ID")
```

```{r}
# right join
data_full_right_join <- data_purchase %>%
  right_join(data_demo, by = "ID")
```

```{r}
# inner_join 
data_full_inner_join <- data_purchase %>%
  inner_join(data_demo, by = "ID")
```

```{r}
# full_join 
data_full_full_join <- data_purchase %>%
  full_join(data_demo, by = "ID")
```

## Data Types

-   *Task*: Check all data types in `data_full` are correct and as expected

```{r}
# can use str() to get the structure of data
# Lina covered this in the induction week
str(data_full)
```

-   *Discussion*: If the variables types are incorrect, think about how would you make it right using `dplyr`?
    -   For instance, we can observe that `Dt_Customer` is of `character` type, we need to convert it to `date` type in R.

```{r}
# use mutate to overwrite the previous Dt_Customer
# use as.Date() to make the conversion from character to date type
data_full <- data_full %>%
  mutate(Dt_Customer = as.Date(Dt_Customer, format = "%d/%m/%Y" ))
```

Now, if we check the data type of `Dt_Customer` using `class()`, it is `date` type now!

```{r}
class(data_full$Dt_Customer)
```

## Missing Values

-   *Tasks*: Are there any missing values in the data?

    -   tip: use `datasummary_skim()`, which reports the number of missing values

```{r}
pacman::p_load(modelsummary)
datasummary_skim(data_full)
```

-   *Tasks*: Clean missing values in the dataset.

    -   tip: use `mean(var, na.rm = T)` to get the average income; and then replace missing values in `data_full` with the average income using `replace()` function. See below an example or check `replace()` help file to find out its syntax.

```{r}
# the below code generates a vector a with 2 NAs (not relevant to case study)
# the 2nd and 4th elements are missing values
# the last line of code replaces any missing value with 2
a <- c(1,NA,3,NA)
replace(a, is.na(a), 2)
```

```{r}
data_full <- data_full %>%
  mutate(Income = replace(Income, is.na(Income), mean(Income,na.rm = T)))
```

# Preliminary Customer Analysis (Descriptive Analytics)

Next, once the final dataset is ready, we can proceed to use descriptive analytics to conduct preliminary customer analysis using `dplyr`.

Descriptive analytics is concerned with summarizing and highlighting patterns in current and historical data in order to assist businesses in comprehending what has occurred thus far. However, it makes no attempt to explain why something occurred or to forecast what may occur in the future.[^2] To answer those questions, businesses must combine descriptive analytics with other types of analysis.

[^2]: "why something occurred" belongs to the scope of causal inference; "forecast what may occur in the future" falls in the scope of predictive analytics.

Your task is to 'get to know' the data by conducting some statistical analysis using Tesco's customer database.

1.  Provide the summary statistics of the cleaned data. From summary statistics, do you already see any insights? (open question; from central tendency and dispersion perspectives)

```{r}
# remember to load package modelsummary before calling this function
datasummary_skim(data_full)
```

2.  Report the percent of customers in each Marital Status group and compare the average spendings in each group. What insights can you draw? Tips: at least two methods to do this task
    -   Tips: use `group_by()` + `summarise()`

To compute the percentage of customers in each marital status group

```{r}
# The below code computes the percentage of customers in each marital status group
data_full %>%
  group_by(Marital_Status)%>%
  summarise(n_customer_each_group = n())%>% #n() counts the # of customer in each group
  ungroup() %>%
  mutate(total_customers = sum(n_customer_each_group))%>% # total number of customers is the sum of number of customers in each marital status group
  mutate(percentage_customers = n_customer_each_group/total_customers)
```

To compare the average spendings of customers in each marital status group

```{r}
data_full %>%
  mutate(total_spending = MntWines + MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts + MntGoldProds) %>% # mutate total spending 
  group_by(Marital_Status)%>% # group by 
  summarise(avg_spending = mean(total_spending))%>% # compute the mean of spending for each group
  ungroup() 
```

In fact, the two questions can be answers in one code block, due to the utmost elegance of R dplyr!

```{r}
data_full %>%
  mutate(total_spending = MntWines + MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts + MntGoldProds) %>% # mutate total spending 
  group_by(Marital_Status)%>%
  summarise(n_customer_each_group = n(),#n() counts the # of customer in each group
            avg_spending = mean(total_spending))%>% # compute the mean of spending for each group
  ungroup() %>%
  mutate(total_customers = sum(n_customer_each_group))%>% # total number of customers is the sum of number of customers in each marital status group
  mutate(percentage_customers = n_customer_each_group/total_customers)
```

3.  Which education group accounts for the largest percentage of customers? Answering this question using `dplyr` only.
    -   tip: in dplyr, there is a function called `n()`, which counts the number of rows in the group after `group_by()`

```{r}
data_demo%>% # Think about why data_demo? what if we use data_full?
  group_by(Education)%>% # group by Education
  summarise(n_customers_in_group = n()) %>% # compute the number of customers in each education group
  ungroup() %>% # important to do the ungroup after each group_by
  mutate(percent_customer = n_customers_in_group/ sum(n_customers_in_group)) %>% # compute the percentage of customers in each group 
  arrange(-percent_customer) # descending order
```

4.  What is the average Total £ spent on wine and fruit products by customers with and without kids?
    -   tip: first mutate a variable called `has_kid`, which equals 1 if the number of kids in the household is larger than 0, and otherwise 0; then group by this `has_kid` variable

```{r}

data_full %>% 
  mutate(has_kid = ifelse(Kidhome>0,1,0)) %>% # generate a new variable indicating if there is kid
  group_by(has_kid) %>%
  summarise(avg_spending_wine = mean(MntWines, na.rm = T),
            avg_spending_fruit = mean(MntFruits, na.rm = T)) %>%
  ungroup()

```

5.  Which product categories have the most sales? Which have sold the least? Use `dplyr` only.

```{r}

data_full %>%
  select(starts_with("Mnt")) %>% # this is a shortcut `select` function by dplyr; check its help manual
  sapply( sum) %>%
  sort()

```

6.  For both complainers and non-complainers, find the total number and also the percent of customers who responded to the offer.

```{r}

data_full %>%
  group_by(Complain) %>%
  summarise(n_responder = sum(Response, na.rm = T),
            percent_responder = n_responder / n(),
            n_non_responder = n() - n_responder,
            percent_non_responder = n_non_responder / n()
            ) %>%
  ungroup()

```

7.  Compute the individual CLV and identify the top 50% customers, assuming the following:

-   the annual retention rate is 60% for complainers and 80% for non-complainers (generate a new column called retention rate, based on complainer or non-complainer)
-   consider 5 years for customer life
-   average COGS 60% - Variable marketing cost: 15% of total spending
-   10% annual discount rate

::: callout-note
## User Defined Function

UDF is covered in the induction week Friday session (by Lina). You can also refer to the following tutorials to learn more about UDF.

-   [simple](https://campus.datacamp.com/courses/data-science-r-basics/programming-basics-3c77f83c-b970-4d34-a0af-ceaf3cdd6868?ex=4)

-   [advanced](https://www.datacamp.com/tutorial/functions-in-r-a-tutorial)
:::

```{r}
# define a function that can compute CLV for each customer.
compute_CLV <- function(retention,N,spending,discount,COGS, marketing_cost){
  # revenue sequence
  revenue_seq <- rep(spending,N)
  
  # profit sequence g = M-c
  profit_seq <- revenue_seq * (1 - COGS - marketing_cost)
  
  # apply retention rate
  
  profit_after_churn <- profit_seq * (retention ^ (seq(1,N) - 1) )
  
  # discount the future profits 
  
  profit_after_churn_discount <- profit_after_churn * ( 1/ (1+discount)) ^ seq(1:N)
  
  # CLV; note that CAC is not available in this case, so the CLV here does not include CAC. If CAC information is available, CLV should consider them.
  
  CLV <- sum(profit_after_churn_discount)
  
  return(CLV)
  
}

data_full <- data_full %>%
  mutate(retention_rate = ifelse(Complain == 1, 0.6, 0.8),# generate individual specific churn rate
         total_spending = MntFishProducts + MntFruits + MntGoldProds + MntMeatProducts + MntSweetProducts + MntWines)%>% 
  rowwise()%>% # row-wise operation for each row to compute the CLV
  mutate(CLV = compute_CLV(retention_rate,5,total_spending/2,0.1,0.6,0.15))%>%
  ungroup() %>%
  arrange(-CLV) 
```
