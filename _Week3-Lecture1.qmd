---
author: Dr Wei Miao
date: "`r (lubridate::ymd('20231004') + lubridate::dweeks(2))`"
date-format: long
institute: UCL School of Management
title: "Class 5 Data Wrangling with R (Part II)"
df-print: kable
colorlinks: true
code-line-numbers: true
format:
  html: 
    toc: true
    number-sections: true
    page-layout: full
    toc-depth: 2
    code-line-numbers: true
    code-copy: hover
  beamer: 
    toc: false
    toc-title: ""
    slide-level: 2
    section-titles: true
    theme: Frankfurt
    colortheme: beaver
    fonttheme: structurebold
    navigation: horizontal
    tbl-colwidths: auto
    fontsize: 9pt
knitr:
  opts_chunk:
    echo: true
    warning: true
    message: true
    error: true
execute: 
  freeze: auto
editor_options: 
  chunk_output_type: inline
---


# Overview

## Class Objectives

-   Understand the major steps to conduct data analytics

-   **Data collection:** Learn how to collect first-hand data

-   **Data cleaning:** Learn how to use the `dplyr` package to collect, load, and clean data

-   **Data analysis:** Learn how to conduct descriptive analytics

# Data Analytics Workflow

## Overview

```{r}
library(knitr)
include_graphics(path = "images/DataAnalyticsSteps.png")
```

## Collect Data

-   **Primary Data:** Data that are generated by the researcher himself/herself, surveys, interviews, experiments, specially designed for understanding and solving the research problem at hand.

-   **Secondary Data:** Existing data generated by the company's or consumer's past activities, as part of organizational record keeping.

```{r}
include_graphics(path = "images/class4_ComparisonOfData.png")
```

## Collect Data: Marketing Surveys

-   In a marketing survey, we typically would like to collect the following information from customers:

    -   purchase intention

    -   willingness to pay (WTP)

    -   shopping basket

    -   share of wallet (SoW)

    -   demographics

-   **Let's see a quick example of how to design a marketing survey!**

-   Useful supplementary readings if you need to design marketing surveys for your term 3 dissertation.

    -   [The quick start guide on how to conduct market research](https://www.surveymonkey.co.uk/mp/market-research-surveys/)

# Data Wrangling with R

## Data Frame Basics

-   Data Frame is the R object that we will deal with most of the time in the MSc program. You can think of `data.frame` as a spreadsheet in excel

-   Each row stands for an `observation`

-   Each column stands for a `variable`; each column should have a **unique** name.

-   Each column must contain the same data type, but the different columns can store different data types.[^1]

[^1]: Compared with matrix, is there any difference despite both being two-dimensional?

## Install and Load the `dplyr` package

-   In R, we will be using the `dplyr` package for data cleaning and manipulation.

```{r}
#| eval: false
install.packages("dplyr")
```

-   Load the package

```{r}
#| message: false
library(dplyr)
```

-   Load a csv format dataset called `data_demo` using `read.csv()`

```{r}
data_demo <- read.csv("https://www.dropbox.com/s/a0v38lpydls2emy/demographics.csv?dl=1")
```

-   To browse the whole dataset, we can simply click the dataset in the environment

## First Look at the Dataset

1.  What variables do the data have?

::: {.content-visible when-format="html"}
```{r}
names(data_demo)
```
:::

2.  What are the types of each variable?

::: {.content-visible when-format="html"}
```{r}
sapply(data_demo,
       class)
```
:::

-   Tip: We can use a function called `str()` short for structure.

::: {.content-hidden when-format="beamer"}
```{r}
str(data_demo)
```
:::


## Common Data Wrangling Operations

-   Select rows (`filter`)

-   Sort rows (`arrange`)

-   Select columns (`select`)

-   Generate new columns (`mutate`)

-   Group aggregation (`group_by`)

-   Merge datasets (`join`)

## Subset Rows Based on Conditions: `filter`

-   We can use `filter()` to select rows that meet certain logical criteria.
    -   The filter operation results in a new dataset, which is a subset of the original dataset after filtering
    -   The number of variables remains the same

![](images/filter.png){fig-align="center"}

-   **Important**: To store the generated new subset of data in RStudio, we need to assign it to a new object.

::: {.content-visible when-format="beamer"}
## Subset Rows Based on Conditions: `filter`

**Example**: From data_demo, find customers who are single

```{r}
# keep only single customers
data_demo_single <- filter(data_demo, Marital_Status == "Single" )

# show the first 5 records using head()
head(data_demo_single,5)
```
:::

::: {.content-hidden when-format="beamer"}
**Example**: From `data_demo`, find customers who are single

```{r}
# keep only single customers
data_demo_single <- filter(data_demo, Marital_Status == "Single" )

```
:::

## The Pipe Operator `%>%`

::: block
### Pipe Operator

`%>%` passes the **object in front** as the **first argument** of the **subsequent function**.
:::

![](images/pipeillustration.png){fig-align="center" width="150"}

## Example of the Pipe Operator `%>%`

```{r}
#| eval: false

# without using pipe
filter(data_demo, Marital_Status == 'Single')

# with pipe 
data_demo %>% filter(Marital_Status == 'Single')

```

## Why Do We Need Pipe Operator for Data Wrangling?

-   **Exercise**: find out **single** customers who have a **PhD** without using pipe.

::: {.content-visible when-format="beamer"}
```{r}
#| eval: false

# based on data_demo, find out customers who are single
data_demo_single <- 

# based on data_demo_single, 
# further find out single customers who have a PhD
data_demo_single_PhD <- 

```
:::

::: {.content-hidden when-format="beamer"}
```{r}
#| eval: false

# based on data_demo, find out customers who are single
data_demo_single <- filter(data_demo, Marital_Status == 'Single')

# based on data_demo_single, find out customers who are single and have PhD
data_demo_single_PhD <- filter(data_demo_single, Education == "PhD")

```
:::

::: {.content-visible when-format="beamer"}
## Why Do We Need Pipe Operator for Data Wrangling?
:::

-   **Exercise**: find out **single** customers who have a **PhD** using pipe.

```{r}
data_demo_single_PhD <- data_demo %>%
  filter(Marital_Status == 'Single') %>%
  filter(Education == 'PhD') %>%
  head() ## You can even continue with more filter steps
```

::: {.content-visible when-format="beamer"}
## Why Do We Need Pipe Operator for Data Wrangling?
:::

-   The pipe works like a conveyor belt in a factory, passing the intermediate outputs from the previous data wrangling step to the next step for further processing until you finish your data wrangling task.

![](images/pipe.png){fig-align="center" width="300"}

## Subset Rows Based on Multiple Conditions: `filter`

-   We can also add multiple criteria using `&`, `|`, and `!` to represent and, or, and not (induction week)

```{r}

data_demo %>%
  filter(Marital_Status == 'Single' & 
           Education == 'PhD') %>%
  head()

```

## Sort Rows: `arrange`

-   **`arrange()`** orders the rows by the values of selected columns.

    -   ascending order by default; for descending order, put a minus sign.

    -   allows multiple sorting variables separated by comma.

-   **Example**: sort customers based on marital status in ascending order and number of teens in descending order.

::: {.content-visible when-format="beamer"}
```{r}
#| eval: false
data_demo %>% 
  arrange(Marital_Status, -Teenhome) 
```
:::

::: {.content-hidden when-format="beamer"}
```{r}
data_demo %>% 
  arrange(Marital_Status, -Teenhome) %>%
  head(10)
```
:::

-   **Exercise:** sort customers based on income in descending order.

::: {.content-hidden when-format="beamer"}
```{r}
data_demo %>% 
  arrange(-Income) %>%
  head(10)
```
:::

## Generate New Variables: `mutate`

-   **`mutate()`** generates new variables in the dataset while preserving existing variables

-   **Example**: create a new variable named `Age` from `Year_Birth`.

::: {.content-visible when-format="beamer"}
```{r}
#| eval: false

data_demo %>%
  mutate(Age = 2023 - Year_Birth) 
```
:::

::: {.content-hidden when-format="beamer"}
```{r}
data_demo %>%
  mutate(Age = 2023 - Year_Birth) %>%
  head(10)
```
:::

-   **Exercise**: create a new variable named `totalkids`, which is the sum of `Kidhome` and `Teenhome`.

::: {.content-hidden when-format="beamer"}
```{r}
data_demo %>%
  mutate(totalkids = Kidhome + Teenhome) %>%
  head(10)
```
:::

## After-Class Exercise

-   Data camp dplyr exercise

-   Read "Preliminary Customer Analyses" dataset, and try to solve the case questions using the techniques learned today

# Data Wrangling Part II

```{r}
#| echo: false
#| message: false
#| warning: false
library(dplyr)
data_demo <- read.csv("https://www.dropbox.com/s/a0v38lpydls2emy/demographics.csv?dl=1")
```

## Data Wrangling Part II

-   Select rows (`filter`)

-   Sort rows (`arrange`)

-   Select columns (`select`)

-   Generate new columns (`mutate`)

-   **Group aggregation (`group_by`): compute statistics for each group**

-   **Merge datasets (`join`): combine datasets from different sources**

## Aggregation by Groups: `group_by`

-   `group_by()` allows us to aggregate data by group and compute statistics for each group

```{r}
#| eval: false
# group by marital status
data_demo %>%
  group_by(Marital_Status) 
```

-   Internally, the dataset is already grouped based on the specified variable(s).

![](images/group_by.png){fig-align="center" width="300"}

## Aggregation by Groups: `group_by() %>% summarise()`

-   After aggregating data, we can use `summarise()` to compute group-specific statistics for us.
    -   Similar to `mutate()` in generating new variables
    -   Different from `mutate()` in that the new variable is computed based on groups.

```{r}
# compute the average income for each marital status group
data_demo %>%
  group_by(Marital_Status) %>% 
  summarise(avg_income = mean(Income,na.rm = T)) %>%
  ungroup()
```

-   What if you replace `summarise()` with `mutate()`?

## Aggregation by Groups: `group_by()` Multiple Groups

-   We can have multiple group variables for `group_by` , such as computing average income for each marital status, education combination

```{r}
#| message: false
# compute the average income for each marital, education group
data_demo %>%
  group_by(Marital_Status,Education) %>% 
  summarise(avg_income = mean(Income,na.rm = T)) %>% 
  ungroup() %>%
  head(5)
```

## Consolidate Multiple Data Frames

-   When consolidating multiple data frames, we have 4 types of joining methods.
-   `left_join()` handles most data join situations, which we will focus on today.

![](images/class4_DataJoin.png){fig-align="center" width="250"}

## `left_join()`

-   `left_join` keeps everything from the **left data frame** and matches as much as it can from the right data frame based on the chosen IDs.

    -   All IDs **in the left data frame** will be retained
    -   If a match can be found, value from the right data frame will be filled in
    -   If a match cannot be found, a missing value will be returned

```{r}
#| eval: false

df_left %>%
  left_join(df_right, by = c('ID' = 'ID') )
```

![](images/left_join.png){fig-align="center" width="200"}

## Caveats for doing `left_join()`

-   We can do 1:1, or M:1 left_joins

-   **Never** do 1:M or M:M left_joins

    ![](images/M%201%20matching.png){width="298"}

## `inner_join()` (optional)

-   `inner_join` only keeps the observations that appear in both data frames
    -   Only common IDs **in both data frames** will be retained

    -   If a match can be found, values will be filled in from both data frames

```{r}
#| eval: false
# Method 1 without pipe operator
inner_join(df_left, df_right, by = 'ID')
# Method 2 with pipe operator
df_left %>%
  inner_join(df_right, by = 'ID')
# Method 3: order of data frames should not matter. Why?
df_right %>%
  inner_join(df_left, by = 'ID')
```

![](images/inner_join.png){fig-align="center" width="200"}

## `full_join()` (optional)

-   `full_join` keeps all observations from both data frames
    -   All IDs **in either data frames** will be retained

    -   If a match can be found, values will be filled in from both data frames

```{r}
#| eval: false
# Method 1 without pipe operator
full_join(df_left, df_right, by = 'ID')
# Method 2 with pipe operator
df_left %>%
  full_join(df_right, by = 'ID')
# Method 3: order of data frames should not matter. Why?
df_right %>%
  full_join(df_left, by = 'ID')
```

![](images/full_join.png){fig-align="center" width="200"}

# Data Cleaning

## Missing Values

-   In R, missing values are represented by the symbol `NA` (i.e., *not available*).

-   Most statistical models cannot handle missing values, so we need to deal with them in R.

    -   Few missing values: remove them from analysis.

    -   Many missing values: need to replace them with appropriate values: mean/median/[imputation](https://www.r-bloggers.com/2021/04/handling-missing-values-in-r/)

## Outliers

-   Sometimes, due to data collection errors, we may have abnormal observations in the data, such as unusually large and small values

-   Winsorization is a common way to deal with outliers

    -   Remove top 1% and bottom 1% observations

# Descriptive Analytics

## Two Major Tasks of Descriptive Analytics

-   You can think of descriptive analytics as **creating a dashboard** to display the key information you would like to know for your business.

1.  **Describe data depending on your business purposes**

    -   "How much do our customers spend each month on average?"

    -   "What percentage of our customers are unprofitable?"

    -   "What is the difference between the retention rates of men and women?"

2.  **Make statistical inferences from data**

    -   "Based on our sample, does the difference between the spending of men and women indicate that men and women respond differently in the customer base at large?"

    -   "Based on our sample, can we conclude that customers who sign up for online banking are more profitable than customers who do not?"

    -   "Based on our test mailing, can we conclude that ad-copy A works better than ad-copy B?"

## Summary Statistics

-   **Summary statistics** are used to summarize a set of observations, in order to communicate the largest amount of information as simply as possible.

-   There are two main types of summary statistics used in evaluation:

    -   **measures of central tendency**: mean, the median, 25 percentile, 75 percentile, the mode, etc.

    -   **measures of dispersion:** range and standard deviation.

-   It's important to include summary statistics table in your dissertation before any statistical analysis!

## Summary Statistics with R

-   In R, a nice package to report summary statistics is `modelsummary`.

-   `datasummary_skim()` is a shortcut to conduct basic summary statistics

-   For more features, refer to the package tutorial [here](https://vincentarelbundock.github.io/modelsummary/articles/datasummary.html)

::: {.content-visible when-format="beamer"}
```{r}
#| eval: false
pacman::p_load(modelsummary)
## Summary statistics for numeric variables
data_demo %>%
  datasummary_skim(type = "numeric")

## Summary statistics for categorical variables
data_demo %>%
  datasummary_skim(type = "categorical")
```
:::

::: {.content-visible when-format="'html'"}
```{r}
pacman::p_load(modelsummary)
data_demo %>%
  datasummary_skim(type = "numeric")

data_demo %>%
  datasummary_skim(type = "categorical")
```
:::

## Case Study: Preliminary Customer Analysis

-   Let's solve the preliminary customer analysis case together in class!
