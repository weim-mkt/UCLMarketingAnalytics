---
author: Dr Wei Miao
institute: UCL School of Management
date: "`r lubridate::ymd('20221006')+lubridate::dweeks(8)`"
title: "Class 17 Difference-in-Differences Design"
df-print: kable
colorlinks: true
code-line-numbers: true
format:
  html: 
    toc: true
    number-sections: true
    page-layout: full
    toc-depth: 2
    code-line-numbers: true
    code-copy: hover
  beamer: 
    toc: false
    toc-title: ""
    slide-level: 2
    section-titles: true
    theme: Frankfurt
    colortheme: beaver
    fonttheme: structurebold
    navigation: horizontal
    tbl-colwidths: auto
    fontsize: 9pt
knitr:
  opts_chunk:
    echo: true
    warning: true
    message: true
    error: true
execute: 
  freeze: auto
editor_options: 
  chunk_output_type: inline
bibliography: references.bib
---

# Natural Experiment

## "Real" Experiments: RCTs

- RCTs are the gold standard of causal inference
    - In an RCT, the treatment is randomized and hence not correlated with any confounding factors

- In practice, however, it's challenging to implement a perfect RCT
    - Crossover and spillover
    - Costly in terms of time and money
    - Potential moral issues^[If you collect any individual data in your dissertation, you need to seek [research ethics approval](https://www.ucl.ac.uk/research-ethics/ethical-approval/do-i-need-ucl-ethical-approval) from UCL.]
    
## "Natural" Experiments

- A **natural experiment** is an empirical study in which individuals are exposed to the experimental and control conditions that are determined by **nature** or by **other factors outside the control of the investigators**. The process governing the exposures arguably **resembles random assignment**.

- Natural experiments are **observational studies** using **secondary data** and are not controlled in the sense of an RCT.

## "Natural" Experiment Examples

- A new government regulation (say, a local COVID-19 lockdown or GDPR) is implemented in city A but not the neighboring city B
    - Residents in city A are treated due to uncontrollable forces but residents in city B are untreated
    
- MSc students get Merit honor for getting 69.9 and Disctinction for getting 70 score
    - Students can definitely work harder to get higher scores, but the 0.1 score may not be controllable by students

## Comparison: RCT & Natural Experiment

:::: {.columns}

::: {.column width="50%"}
**RCT**

1. Assignment of treatment is purely randomized

2. Treatment is under control of a researcher

3. Primary data

4. We can proactively design an RCT for the research questions we have

:::

::: {.column width="50%"}
**Natural Experiment**

1. Assignment of treatment is "as-if" randomized

2. Treatment is not controlled by a researcher

3. Secondary data

4. We can only look for natural experiments from current data that fit our questions

:::

::::

# DiD on Primary Data

## A Motivating Example

-   In the RCT lecture, we learned how to design an A/B testing in 5 steps to help Tom evaluate the causal impact of a loyalty program on customers' retention rate.

-   We discussed that *the unit of randomization* should not be at the region level.

    -   East London versus West London randomization would cause failed randomization checks

-   However, in reality, individual-level randomization may be too costly or infeasible, and we may need to do a region-level A/B testing. In this case, how can design the A/B testing to avoid failed randomization?

## Proposal 1: Before-After Comparison on East London

1.  Keep status quo (**no loyalty program)** in East London for 1 month; collect customer retention data for this month.
2.  **Then Introduce the loyalty program** in East London; collect customer retention data for another 1 month.
3.  Compare the before-after difference in retention rate by a t-test or running the following regression:

$$
Retention_{i, t}=\alpha+\beta_{1} Post_{i}+\mu_{i, t}
$$

**Can this difference tell us the causal effect of the new pricing?**[^1]

[^1]: See html version for answers.

::: {.content-visible when-format="html"}
-   No, because the variable $post$ is confounded with seasonality. Even without the loyalty program, customers' retention may already change with time due to seasonality. So this simple before-after difference cannot tease out the causal effect of the loyalty program.
:::

## Proposal 2: East-West London Comparison

1.  Randomize which region (East London/West London) would receive the loyalty program, and then introduce the loyalty program in the treatment region.
2.  Collect customer retention data for both regions for a month.
3.  Compare the treatment-control difference in retention rate by a t-test or running the following regression:

$$
Retention_{i, t}=\alpha+\beta_{1} Treated_{i}+\mu_{i, t}
$$

**Can this difference tell us the causal effect of the loyalty program?**[^2]

[^2]: See html version for answers.

::: {.content-visible when-format="html"}
-   No, because customers in East London and West London are intrinsically different. Even without the loyalty program, we may already see a difference in their retention rate. So the simple treatment-control comparison cannot tease out the causal effect of the loyalty program.
:::

## Proposal 3: Difference-in-Differences

1.  Keep status quo (no loyalty program) in both East and West London for 1 month; collect data on customer retention for this month in both regions.
    -   Compute the difference in retention rate $Diff_{pre} = Y_{treated,pre} - Y_{control,pre}$, which measures the pre-existing difference across the treatment and control group even without the loyalty program.
2.  Randomize which region (East London/West London) would receive the loyalty program, and then introduce the loyalty program in the treatment region; collect customer retention data for both regions for another 1 month
    -   Compute the difference in retention rate across the treatment and control group in this second month: $Diff_{post} = Y_{treated,post} - Y_{control,post}$, which measures the the total difference across the treatment and control group due to (1) pre-existing difference; and (2) treatment effect.
3.  $DiD = Diff_{post} - Diff_{pre}$ or by running the below regression. $DiD$ can measure the causal effect of loyalty program on retention rate.

$$
Retention_{i, t}=\beta_0+ \beta_{1} Post_{i}+\beta_{2} Treated_{i}+\beta_{3}  Treated_{i} \times Post_{i}  + \mu_{i, t}
$$

## Difference-in-Differences

-   Difference-in-differences (DiD or DD) is a statistical technique used in economics and business that attempts to mimic an experimental research design using observational data (secondary data), by studying the differential effect of a treatment on a 'treatment group' versus a 'control group' in a natural experiment.

-   In practice, DiD can also be combined with an RCT, if true randomization is costly or infeasible.

## DiD Estimator: Graphical Illustration

::: {.content-visible when-format="beamer"}
![](images/DiDGraph.png){fig-align="center" width="300"}
:::

::: {.content-visible when-format="html"}
![](images/DiDGraph.png){fig-align="center"}
:::

## DiD Estimator: Alternative Illustration

-   We can also use linear regression to quantify the treatment effects from a Diff-in-Diff experiment:

$$
Outcome_{i, t}=\beta_0+ \beta_{1} Post_{t}+\beta_{2} Treated_{i}+\beta_{3}  Treated_{i} \times Post_{t}  + \mu_{i, t}
$$

-   The idea of running a regression is to control the confounding factors: (1) $Post_{t}$ can control for the seasonality for all customers (2) $Treated_{i}$ can control for the pre-existing difference between the treatment group and control group.

-   Therefore, $\beta_3$ is the actual treatment effect, after teasing out (1) seasonality and (2) pre-existing differences.

## Parallel Pre-trend Assumption

-   The requirement for a valid DiD analysis is that there is **no differential trend** between the treatment and control group before the treatment happens, or we must need **parallel pre-trend**.

::: {.content-visible when-format="beamer"}
![](images/DiDPretrend.png){fig-align="center" width="300"}
:::

::: {.content-visible when-format="html"}
![](images/DiDPretrend.png){fig-align="center"}
:::

# DiD Analyses with R

## Sample Data

-   `base_did` is a data frame with 1,040 observations and 6 variables named $y$, $x1$, $id$, $period$, $post$ and $treat$.
    -   $y$: The outcome variable (e.g., retention) affected by the treatment (e.g., loyalty program).
    -   $x1$: standardized customer income.
    -   $id$: Identifier of the individual.
    -   $period$: From 1 to 10
    -   $post$: Indicator taking value 1 if the period is strictly greater than 5, 0 otherwise.
    -   $treat$: Indicator taking value 1 if the individual is treated, 0 otherwise.

## Dataset

```{r}
pacman::p_load(fixest,modelsummary)
data("base_did")
head(base_did,8)
```

## Estimation of DiD

> \[in `help(feols)`\] ... You can interact a numeric variable with a "factor-like" variable by using i(factor_var, continuous_var, ref), where continuous_var will be interacted with each value of factor_var and the argument ref is a value of factor_var taken as a reference (optional).

\

```{r}
est_did = feols(
  fml = y ~ x1 + i(period, treat, 1) | 
                  id + period, 
                data = base_did)
```

## Report the Regression Results

\tiny

```{r}
#| echo: false
modelsummary(est_did,
             stars = TRUE)
```

## Plot Estimates of DiD

```{r}
iplot(est_did)
```

## Pre-trend Test

-   The treatment happens in period 5, we need to make sure that, the differences across the treatment group and control group are not statistically changing over time.

-   In terms of the regression coefficients, we need to make sure that the interactions between $treated$ and $period$ before the treatment are statistically insignificant.

# DiD on Secondary Data

## DiD on Secondary Data

-   Although DiD method can be combined with RCT to collect primary data, DiD is more commonly used on secondary data.

-   For your dissertation project, once you collect data from the companies, you can also work on a causal inference project using the DiD method.

## Causal Effect of Surge Pricing on Drivers

-   @miaoEffectsSurgePricing2022 study the causal effects of surge pricing on driver labor supply decisions. The ridesharing company introduced surge pricing in one city but not the other, such that we have a nice DiD setup:

    -   Treatment group: drivers in the city that implemented the surge pricing
    -   Control group: drivers in the city that did not implement the surge pricing

## Framework of Analyses

![](images/SurgePricing.png){fig-align="center" width="300"}

-   Weekly income
    -   Surge pricing leads to higher weekly income
-   Intensive margin of labor supply
    -   Surge pricing leads to decreased daily income due to intensified competition
-   Extensive margin of labor supply
    -   Drivers have to work more days to make up of the decreased daily revenue

## Clustering for Heterogeneity Analyses

![](images/SurgePricingClustering.png){fig-align="center" width="300"}

-   We use K-means clustering to segment out 2 clusters of drivers: full time and part time drivers.

    -   Full-time drivers have decreased weekly revenue due to capacity constraint.

    -   Part-time drivers flooded into the market and have increased weekly revenues by working more days.

    -   Although surge pricing enlarged the total pie for the company, the benefit was unevenly distributed among drivers.
