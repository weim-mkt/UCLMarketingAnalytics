---
author: Dr Wei Miao
date: "`r (lubridate::ymd('20221006')+lubridate::dweeks(2))|> format('%a, %b %d %Y')`"
institute: UCL School of Management
title: "Class 6 Predictive Analytics for STP"
df-print: kable
colorlinks: true
code-line-numbers: true
format:
  html: 
    toc: true
    number-sections: true
    page-layout: full
    toc-depth: 2
    code-line-numbers: true
    code-copy: hover
  beamer: 
    toc: false
    toc-title: ""
    slide-level: 2
    section-titles: true
    theme: Frankfurt
    colortheme: beaver
    fonttheme: structurebold
    navigation: horizontal
    tbl-colwidths: auto
    fontsize: 9pt
knitr:
  opts_chunk:
    echo: true
    warning: true
    message: true
    error: true
execute: 
  freeze: auto
editor_options: 
  chunk_output_type: inline
---

# Overview

## Our Journey So Far

-   The core of any business decision is **break-even analysis** (cost-benefit analysis)

    -   BEQ; NPV; CLV (Week 1 and Week 2)

-   For better profitability management, we can work on either reducing the **cost** or boosting the **benefit**.

![](images/paste-361EFA3E.png){fig-align="center" width="250"}

## Roadmap of Predictive Analytics

-   In Weeks 3 and 4, we will learn how to utilize predictive analytics to reduce marketing costs and improve marketing efficiency

![](images/paste-613B4ABA.png){fig-align="center" width="400"}

## Learning Objectives

-   Understand the concept of statistical learning

-   Understand the concept of unsupervised learning and how to apply clustering analyses for customer segmentation

# Predictive Analytics

## Types of Predictive Analytics

-   Supervised Learning
    -   Observe both X and Y =\> Want to predict Y for new data
-   Unsupervised Learning
    -   Only observe X =\> Want to uncover unknown subgroups
-   Reinforcement Learning
    -   Rewards and punishments =\> Learn the best decision rules
    -   [Dynamic Coupon Targeting Using Batch Deep Reinforcement Learning: An Application to Livestream Shopping](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4146060)

In Term 2, you will learn predictive analytics models systematically. By then, think about how those techniques can be applied back to these case studies.

## Types of Predictive Analytics

![](images/PredictiveAnalyticsTypes.png){fig-align="center" width="350"}

# Segmentation with Unsupervised Learning

## Customer Segmentation

Segmentation is the process of dividing customers into meaningful groups based on any characteristics relevant to design and execution of your marketing strategy. It assumes that different customer groups offer different levels of value to the company and/or require different marketing programs to succeed with (e.g., based on different goals and needs).

## Conventional Ways for Customer Segmentation

-   **Customer value segmentation** is for targeting decisions based on customers' potential long-term financial and strategic value to your company.

-   **Benefit segmentation** is for positioning and marketing mix design on the basis of customer and consumer goals or usage, the needs, wants, problems and the trade-offs they are willing to make across benefits (e.g., price vs. quality).

-   **Psychographic segmentation** is for positioning and marketing mix design based on the psychology of the customer and consumer, including attitudes, identity, lifestyle, personality, etc.

-   **Demographic segmentation** uses variables such as age, gender, income, family life cycle, educational qualification, socio-economic status, religion, company size and income, etc. These serve as proxies for goals, preferences or psychographics, as well as to characterize segments for marketing mix decisions.

Conventional segmentation methods require heavy human judgments. A more sensible way is to "let the data speak".

## Commonly Used Clustering Algorithms

-   K-means clustering
    -   The number of clusters need to be pre-speciﬁed
-   Hierarchical clustering
    -   Observations are clustered in a tree-structured graph or dendrogram. No need to pre-determine the number of clusters.

## K-Means Clustering

K-means clustering is one of the most commonly used unsupervised machine learning algorithms for partitioning a given data set into a set of *k* groups (i.e. *k* clusters), where *k* represents the number of groups pre-specified by the analyst.

It can classify customers into multiple segments (i.e., clusters), such that customers within the same cluster are as similar as possible, whereas customers from different clusters are as dissimilar as possible. 

-   Input: customer data (characteristics of interest) and the number of clusters
-   Output: clusters
    -   Let $C_1 , C_2 , · · · , C_k$ be the clusters
    -   Every customer is categorized to only one of the clusters

## K-Means Clustering: Intuition

![](images/kmeansViz.png){fig-align="center" width="350"}

## Implementation of K-Means in R for Tesco

1.  Decide to do customer segmentation based on *total spending* and *income*

```{r}
#| echo: false
data_demo <- read.csv(file = "https://www.dropbox.com/s/a0v38lpydls2emy/demographics.csv?dl=1",
                      header = T)

# Load purchase history data, and call it data_purchase
data_purchase <- read.csv(file = "https://www.dropbox.com/s/de435r8zdxydnhg/purchase.csv?dl=1" , header = T)
pacman::p_load(dplyr)
# left join
data_full <- data_purchase %>%
  left_join(data_demo, by = "ID") %>%
  mutate(total_spending = MntFishProducts + MntFruits + MntGoldProds + MntMeatProducts + MntSweetProducts + MntWines)%>%
  mutate(Income = replace(Income, is.na(Income), mean(Income,na.rm =T)))
```

![](images/k-means.png){fig-align="center" width="300"}

-   `x`: data with selected variables to apply K-means
-   `centers`: number of clusters
-   `iter.max`: the maximum number of iterations allowed
-   `nstart`: how many random sets should be chosen
-   `algorithm`: which algorithm to choose; default often works
-   `trace`: do you want to trace intermediate steps?

## Implementation of K-Means in R for Tesco

-   Need to re-scale the two variables using `scale()`, because the two variables are of very different scales

    -   **This is extremely important!**

```{r}
set.seed(888)
data_kmeans <- data_full%>%
  select(Income,total_spending)%>%
  mutate(Income = scale(Income),
         total_spending = scale(total_spending))

result_kmeans <- kmeans(data_kmeans,
                        centers = 2,
                        nstart = 10)
```

## Implementation of K-Means in R for Tesco

2.  Examine the returned object, `result_kmeans`

::: {.content-visible when-format="html"}
```{r}
#| eval: true
str(result_kmeans)
```
:::

::: {.content-visible when-format="beamer"}
```{r}
#| eval: false
str(result_kmeans)
```
:::

-   `cluster`: A vector of integers (from 1:k) indicating the cluster to which each point is allocated.

-   `centers`: A matrix of cluster centers.

-   `totss`: The total sum of squares.

-   `withinss`: Vector of within-cluster sum of squares, one component per cluster.

-   `tot.withinss`: Total within-cluster sum of squares, i.e. sum(withinss).

-   `betweenss`: The between-cluster sum of squares, i.e. \$totss-tot.withinss\$.

-   `size`: The number of points in each cluster.

## Implementation of K-Means in R for Tesco

3.  Visualize the clusters

```{r}
#| out-width: "70%"
#| fig-align: "center"
pacman::p_load(cluster,factoextra)
set.seed(888)
fviz_cluster(result_kmeans,
             data = data_kmeans)
```

## Implementation of K-Means in R for Tesco

4.  Determine the optimal number of clusters using statistical criteria

-   Gap Method

```{r}
#| message: false
#| warning: false
#| cache: true
#| out-width: "50%"
#| fig-align: "center"

set.seed(888)
gap_stat <- clusGap(data_kmeans, 
                    FUN = kmeans,
                    K.max = 10,
                    B = 50)
fviz_gap_stat(gap_stat)
```

## Implementation of K-Means in R for Tesco

4.  Determine the optimal number of clusters using statistical criteria

-   Silhouette method

```{r}
#| out-width: "70%"
#| fig-align: "center"
set.seed(888)
fviz_nbclust(data_kmeans, kmeans, method = "silhouette")
```

## Implementation of K-Means in R for Tesco

5.  Compare the CLV in the two segments, and decide which segment to serve.
    -   This is a general idea of segmentation and targeting using unsupervised learning
    -   Finish this exercise after class

## Pros and Cons of K-means Clustering

Advantages

-   Easy to implement and explain

-   Computationally eﬃcient

Drawbacks

-   As the number of variable increases, curse of dimensionality problem occurs

-   Sensitive to outliers

-   Sensitive to initial seeds

## After-Class Readings

-   Useful source: [K-means Cluster Analysis](https://uc-r.github.io/kmeans_clustering)
